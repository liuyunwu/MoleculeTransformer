{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecule transformers\n",
    "\n",
    "## 1. input embedding \n",
    "\n",
    "## 2. Self attention and Feed forward\n",
    "\n",
    "## 3. details\n",
    "\n",
    "Activation function : gelu\n",
    "\n",
    "The maximum length of positional embedding : 100\n",
    "\n",
    "masked probability for each token : 0.15\n",
    "\n",
    "masking probability : 0.8 | trainsition probability : 0.2\n",
    "\n",
    "## 4. Questions\n",
    "Is it OK to remain the synonyms for SMILES representations?\n",
    "\n",
    "Should we use mask?? or not??\n",
    "\n",
    "## 5. Note\n",
    "Somehow, (guessing: just underflow problems of the CPU itself) CPU-based learning show poor convergence speed.\n",
    "\n",
    "Most of them just being (C,4). We should add the class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torchtext\n",
    "import random\n",
    "import math\n",
    "from torchtext.data import Iterator\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.ninp = ninp\n",
    "        self.src_mask = None\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder = torch.nn.Embedding(ntoken, ninp)\n",
    "        \n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout, activation='gelu')\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.decoder = torch.nn.Linear(ninp, ntoken) ## embedded -> seq\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != src.size(0):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(src.size(0)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        pos_emb = self.encoder(src) * math.sqrt(self.ninp)\n",
    "\n",
    "        mol_token_emb = self.pos_encoder(None) ### Input embedding = positional embedding + normal embedding\n",
    "        input_emb = pos_emb + mol_token_emb\n",
    "        \n",
    "        output = self.transformer_encoder(input_emb, self.src_mask) ### Self-attention layers : dim = ninp\n",
    "        output = self.decoder(output) ### decoding\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_file = './CID-SMILES_1M_train.txt'\n",
    "\n",
    "smile_mol_tokenizer = torchtext.data.Field(init_token='<BEGIN>',\n",
    "                                          pad_token='<PAD>',\n",
    "                                          tokenize=list,\n",
    "                                          eos_token='<END>',\n",
    "                                          fix_length=100,\n",
    "                                          batch_first=True) \n",
    "\n",
    "smile_data_training = torchtext.data.TabularDataset(path=train_file,\n",
    "                                          format='csv',\n",
    "                                          fields=[('input', smile_mol_tokenizer), ('output', smile_mol_tokenizer)])\n",
    "\n",
    "\n",
    "train_data, test_data = smile_data_training.split(split_ratio=0.7)\n",
    "smile_mol_tokenizer.build_vocab(smile_data_training)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_batch = Iterator(train_data, batch_size=128, device=device, repeat=False)\n",
    "test_batch = Iterator(test_data, batch_size=128, device=device, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = len(smile_mol_tokenizer.vocab.stoi)\n",
    "mol_emsize = 128 # Embedded molecule sizes\n",
    "n_layers = 8 # Number of attentions and feed-forwards\n",
    "n_head = 8 # Attention heads\n",
    "n_hid = 512 # feed forward dim\n",
    "\n",
    "counts = list(smile_mol_tokenizer.vocab.freqs.values())\n",
    "sum_counts = sum(counts)\n",
    "class_weights = list(map(lambda x: math.log(sum_counts/x), counts))\n",
    "class_weights = [1., 1., 1., 1.] + class_weights\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))\n",
    "model = TransformerModel(n_tokens, mol_emsize, n_head, n_hid, n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 5469 batches | lr 0.00 | ms/batch 214.24 | loss  0.93 | ppl     2.54\n",
      "| epoch   1 |   400/ 5469 batches | lr 0.00 | ms/batch 208.97 | loss  0.34 | ppl     1.41\n",
      "| epoch   1 |   600/ 5469 batches | lr 0.00 | ms/batch 209.85 | loss  0.33 | ppl     1.38\n",
      "| epoch   1 |   800/ 5469 batches | lr 0.00 | ms/batch 209.61 | loss  0.32 | ppl     1.38\n",
      "| epoch   1 |  1000/ 5469 batches | lr 0.00 | ms/batch 211.71 | loss  0.32 | ppl     1.37\n",
      "| epoch   1 |  1200/ 5469 batches | lr 0.00 | ms/batch 214.79 | loss  0.31 | ppl     1.37\n",
      "| epoch   1 |  1400/ 5469 batches | lr 0.00 | ms/batch 210.49 | loss  0.32 | ppl     1.37\n",
      "| epoch   1 |  1600/ 5469 batches | lr 0.00 | ms/batch 217.20 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  1800/ 5469 batches | lr 0.00 | ms/batch 217.91 | loss  0.31 | ppl     1.37\n",
      "| epoch   1 |  2000/ 5469 batches | lr 0.00 | ms/batch 221.50 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  2200/ 5469 batches | lr 0.00 | ms/batch 221.48 | loss  0.31 | ppl     1.37\n",
      "| epoch   1 |  2400/ 5469 batches | lr 0.00 | ms/batch 221.53 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  2600/ 5469 batches | lr 0.00 | ms/batch 221.45 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  2800/ 5469 batches | lr 0.00 | ms/batch 221.60 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  3000/ 5469 batches | lr 0.00 | ms/batch 218.83 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  3200/ 5469 batches | lr 0.00 | ms/batch 208.36 | loss  0.31 | ppl     1.36\n",
      "| epoch   1 |  3400/ 5469 batches | lr 0.00 | ms/batch 209.96 | loss  0.31 | ppl     1.36\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    for batch in train_batch:\n",
    "        data, targets = batch.input, batch.output\n",
    "        #targets_onehot = torch.nn.functional.one_hot(targets, num_classes=72)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predicts = model(data)\n",
    "        #print(predicts.size(), targets_onehot.size())\n",
    "        #print(predicts.view(-1, n_tokens).size(), targets_onehot.size())\n",
    "        loss = criterion(predicts.view(-1, n_tokens), targets.view(-1))\n",
    "        loss.backward()\n",
    "        #print(predicts, targets)\n",
    "        #print(torch.max(predicts, 1)[1])\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, i, len(train_batch), scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "        i += 1\n",
    "\n",
    "def evaluate(eval_model):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch in test_batch:\n",
    "            data, targets = batch.input, batch.output\n",
    "            predicts = eval_model(data)\n",
    "            output_flat = output.view(-1, n_tokens)\n",
    "            total_loss += len(data) * criterion(predicts.view(-1, n_tokens), targets.view(-1)).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4, 11,  4,  4, 12,  4, 70, 11,  4,  4, 12,  8,  4,  6,  5,  9,  7,\n",
      "         4, 13,  5,  4,  4,  5,  4,  4,  5,  4, 13,  7, 10, 25,  4, 11,  4,  4,\n",
      "        12,  4,  8, 11,  4,  4, 12,  6,  4,  6,  8,  9,  7,  4, 13,  5,  4,  4,\n",
      "         5,  4,  4,  8,  4, 13,  7, 10,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1], device='cuda:0')\n",
      "tensor([ 2,  4, 11,  4,  4, 12,  4, 18, 11,  4,  4, 12, 18,  4,  6,  5,  9,  7,\n",
      "         4, 13,  5,  4,  4,  5,  4,  4,  5,  4, 13,  7, 10, 25,  4, 11,  4,  4,\n",
      "        12,  4, 13, 11,  4,  4, 12,  6,  4,  6, 24,  9,  7,  4, 13,  5,  4,  4,\n",
      "         5,  4,  4, 24,  4, 13,  7, 10,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1], device='cuda:0') torch.Size([128, 100])\n",
      "tensor([ 2,  4, 11,  4,  4, 12,  4,  4, 11,  4,  4, 12,  6,  4,  6,  5,  9,  7,\n",
      "         4, 13,  5,  4,  4,  5,  4,  4,  5,  4, 13,  7, 10, 25,  4, 11,  4,  4,\n",
      "        12,  4,  4, 11,  4,  4, 12,  6,  4,  6,  5,  9,  7,  4, 13,  5,  4,  4,\n",
      "         5,  4,  4,  5,  4, 13,  7, 10,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1], device='cuda:0') torch.Size([128, 100])\n",
      "0 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for batch in train_batch:\n",
    "    predicts = model(batch.input)\n",
    "    #print(predicts, predicts.size())\n",
    "    print(batch.input[0])\n",
    "    masked_num = 0\n",
    "    hit = 0\n",
    "    for i in range(len(batch.output[0])):\n",
    "        if batch.input[0][i] == 8:\n",
    "            masked_num += 1\n",
    "            if batch.output[0][i] == torch.max(predicts, 2)[1][0][i]:\n",
    "                hit += 1\n",
    "            \n",
    "    print(torch.max(predicts, 2)[1][0], torch.max(predicts, 2)[1].size())\n",
    "    print(batch.output[0], batch.output.size())\n",
    "    print(hit, masked_num)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some meaningless tests(sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4, 11,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  8,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1]]) torch.Size([512, 100])\n",
      "tensor([[ 2,  4, 11,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  6,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1],\n",
      "        [ 2,  4,  4,  ...,  1,  1,  1]]) torch.Size([512, 100])\n",
      "torch.Size([100, 72])\n",
      "tensor([[[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]]])\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_onehot(x, dim, n_classes):\n",
    "    y = torch.zeros(dim, n_classes)\n",
    "    y[range(y.shape[0]), x] = 1\n",
    "    return y\n",
    "    \n",
    "for batch in train_batch:\n",
    "    print(batch.input, batch.input.size())\n",
    "    print(batch.output, batch.output.size())\n",
    "    print(to_onehot(batch.output,100,72).size())\n",
    "    print(torch.nn.functional.one_hot(batch.input, num_classes=72))\n",
    "    if 3 in batch.input[0]:\n",
    "        print(\"valid\")\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5469"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_mol_tokenizer.vocab.extend\n",
    "len(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'C': 31798080, '=': 12116178, '(': 8152226, ')': 8151141, ' ': 5617883, 'O': 5263368, 'N': 3874771, '1': 3511878, '2': 2976778, '3': 1881824, '[': 1449974, ']': 1449818, '@': 1329865, '4': 842379, 'H': 837995, 'S': 669320, 'l': 530728, 'F': 413261, '5': 287084, '+': 266362, '-': 260152, '.': 189588, '#': 157056, 'B': 153817, 'r': 148943, '/': 118896, '6': 109514, 'P': 78212, 'i': 62042, '7': 53697, 'I': 49771, '\\\\': 45922, '8': 36877, 'a': 32851, '9': 29761, 'e': 27934, 'A': 26198, 'n': 25904, 'g': 24982, 's': 24642, 'u': 24379, 'o': 24262, 'M': 23906, 't': 23409, 'T': 23050, 'K': 22859, 'R': 22364, 'Z': 22310, 'b': 22234, 'd': 22149, 'W': 22002, 'L': 21811, 'G': 21696, 'c': 21515, 'h': 21403, 'k': 21370, 'm': 21358, 'V': 21358, '0': 21323, '%': 21252, 'X': 21247, 'E': 21224, 'Y': 21185, 'p': 21089, 'y': 21061, 'D': 21020, 'f': 21018, 'U': 20982})\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fd72b7262b0>>, {'<unk>': 0, '<PAD>': 1, '<BEGIN>': 2, '<END>': 3, 'C': 4, '=': 5, '(': 6, ')': 7, ' ': 8, 'O': 9, 'N': 10, '1': 11, '2': 12, '3': 13, '[': 14, ']': 15, '@': 16, '4': 17, 'H': 18, 'S': 19, 'l': 20, 'F': 21, '5': 22, '+': 23, '-': 24, '.': 25, '#': 26, 'B': 27, 'r': 28, '/': 29, '6': 30, 'P': 31, 'i': 32, '7': 33, 'I': 34, '\\\\': 35, '8': 36, 'a': 37, '9': 38, 'e': 39, 'A': 40, 'n': 41, 'g': 42, 's': 43, 'u': 44, 'o': 45, 'M': 46, 't': 47, 'T': 48, 'K': 49, 'R': 50, 'Z': 51, 'b': 52, 'd': 53, 'W': 54, 'L': 55, 'G': 56, 'c': 57, 'h': 58, 'k': 59, 'V': 60, 'm': 61, '0': 62, '%': 63, 'X': 64, 'E': 65, 'Y': 66, 'p': 67, 'y': 68, 'D': 69, 'f': 70, 'U': 71})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0806, 2.4417, 2.0455, 2.8792, 2.4419,\n",
       "        2.8141, 4.1685, 4.1686, 3.1855, 5.8629, 4.9415, 3.2839, 4.2549, 7.0884,\n",
       "        7.8402, 5.8865, 5.1735, 3.4492, 5.4237, 8.3790, 8.3403, 8.1179, 8.3462,\n",
       "        8.3184, 3.9078, 4.7115, 8.3566, 8.4024, 6.4442, 6.6695, 8.3863, 8.3863,\n",
       "        8.3654, 7.6208, 8.3926, 8.3101, 8.0546, 8.4004, 8.2296, 4.7168, 8.2589,\n",
       "        8.3880, 6.2029, 8.3913, 5.7880, 6.7517, 8.3842, 8.3990, 6.3912, 8.1934,\n",
       "        7.5403, 7.9558, 7.4644, 8.3427, 8.3945, 7.3200, 8.2736, 8.3916, 8.1821,\n",
       "        8.3500, 8.4041, 8.3706, 8.4023, 8.2947, 6.4120, 8.2541, 8.2433, 8.3858])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smile_mol_tokenizer.numericalize(train_data.examples[0].smile_mol) , train_data.examples[0].smile_mol\n",
    "print(smile_mol_tokenizer.vocab.freqs)\n",
    "print(smile_mol_tokenizer.vocab.stoi)\n",
    "counts = list(smile_mol_tokenizer.vocab.freqs.values())\n",
    "sum_counts = sum(counts)\n",
    "class_weights = list(map(lambda x: math.log(sum_counts/x), counts))\n",
    "class_weights = [1., 1., 1., 1.] + class_weights\n",
    "len(class_weights)\n",
    "torch.Tensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Iterator' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-072405041efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Iterator' object has no attribute 'size'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
